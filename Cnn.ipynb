{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "\n",
    "import matplotlib\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import KMNIST\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import time\n",
    "import dask.array as da\n",
    "import mne\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "tasks = [\"task-med1breath_eeg\",\n",
    "\"task-med2_eeg\",\n",
    "\"task-think1_eeg\",\n",
    "\"task-think2_eeg\"]\n",
    "\n",
    "eegDir = \"D:\\RnnMachineLearning\\eegData\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the [id,epoch10sec,MeditationState(Boolean)] data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "517e3ad77f3f4d088d716f17cce0c205"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ecfc9fef1cbd4c8693845749ff5d8922"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File being read: sub-001_task-med1breath_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-001_task-med1breath_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 620543  =      0.000 ...   605.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n",
      "File being read: sub-001_task-med2_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-001_task-med2_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 618495  =      0.000 ...   603.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n",
      "File being read: sub-001_task-think1_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-001_task-think1_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 620543  =      0.000 ...   605.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n",
      "File being read: sub-001_task-think2_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-001_task-think2_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 621567  =      0.000 ...   606.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c877d836184743359fabd3583f136618"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File being read: sub-002_task-med1breath_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-002_task-med1breath_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 620543  =      0.000 ...   605.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n",
      "File being read: sub-002_task-med2_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-002_task-med2_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 619519  =      0.000 ...   604.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n",
      "File being read: sub-002_task-think1_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-002_task-think1_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 648191  =      0.000 ...   632.999 secs...\n",
      "Using data from preloaded Raw for 63 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(63, 72, 10240)\n",
      "File being read: sub-002_task-think2_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-002_task-think2_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 620543  =      0.000 ...   605.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e59244bf84349d58b0534bf702f8ffa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File being read: sub-003_task-med1breath_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-003_task-med1breath_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 616447  =      0.000 ...   601.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n",
      "File being read: sub-003_task-med2_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-003_task-med2_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 617471  =      0.000 ...   602.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n",
      "File being read: sub-003_task-think1_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-003_task-think1_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 621567  =      0.000 ...   606.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n",
      "File being read: sub-003_task-think2_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-003_task-think2_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 627711  =      0.000 ...   612.999 secs...\n",
      "Using data from preloaded Raw for 61 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(61, 72, 10240)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bcbe0b5642c46a09ab68087f9eeec9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File being read: sub-004_task-med1breath_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-004_task-med1breath_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 630783  =      0.000 ...   615.999 secs...\n",
      "Using data from preloaded Raw for 61 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(61, 72, 10240)\n",
      "File being read: sub-004_task-med2_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-004_task-med2_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 627711  =      0.000 ...   612.999 secs...\n",
      "Using data from preloaded Raw for 61 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(61, 72, 10240)\n",
      "File being read: sub-004_task-think1_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-004_task-think1_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1236991  =      0.000 ...   604.000 secs...\n",
      "Using data from preloaded Raw for 60 events and 20480 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 20480)\n",
      "Wrong size: 20480\n",
      "File being read: sub-004_task-think2_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-004_task-think2_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 1241087  =      0.000 ...   606.000 secs...\n",
      "Using data from preloaded Raw for 60 events and 20480 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 20480)\n",
      "Wrong size: 20480\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1edcc2ea464743ae98f7f3e904a37cbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File being read: sub-005_task-med1breath_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-005_task-med1breath_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 616447  =      0.000 ...   601.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n",
      "File being read: sub-005_task-med2_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-005_task-med2_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672767  =      0.000 ...   656.999 secs...\n",
      "Using data from preloaded Raw for 65 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(65, 72, 10240)\n",
      "File being read: sub-005_task-think1_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-005_task-think1_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 623615  =      0.000 ...   608.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n",
      "File being read: sub-005_task-think2_eeg.bdf\n",
      "Extracting EDF parameters from D:\\RnnMachineLearning\\eegData\\sub-005_task-think2_eeg.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 615423  =      0.000 ...   600.999 secs...\n",
      "Using data from preloaded Raw for 60 events and 10240 original time points ...\n",
      "0 bad epochs dropped\n",
      "(60, 72, 10240)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(1,6)):\n",
    "    listData =[]\n",
    "    if i<10:\n",
    "        sub = \"00\"+str(i)\n",
    "    else:\n",
    "        sub= \"0\"+str(i)\n",
    "\n",
    "    for task in tqdm(tasks):\n",
    "        fileName = f\"sub-{sub}_{task}.bdf\"\n",
    "        medState = \"med\" in fileName\n",
    "        print(\"File being read:\",fileName)\n",
    "        ex = mne.io.read_raw_bdf(os.path.join(eegDir,fileName),preload=True)\n",
    "\n",
    "        if ex.info.get(\"nchan\")==80:\n",
    "            ex.drop_channels(('GSR1', 'GSR2', 'Erg1', 'Erg2', 'Resp', 'Plet', 'Temp', 'Status'))\n",
    "        else:\n",
    "            ex.drop_channels(('Status'))\n",
    "        Epochs = mne.make_fixed_length_epochs(ex,duration=10,verbose=False)\n",
    "        arrEpochs = Epochs.get_data()\n",
    "        print(arrEpochs.shape)\n",
    "        if arrEpochs.shape[2]==20480:\n",
    "            print(\"Wrong size:\",20480)\n",
    "            continue\n",
    "\n",
    "        for i in arrEpochs:\n",
    "\n",
    "            listData.append([sub,i,medState])\n",
    "    da.to_npy_stack(f\"D:/RnnMachineLearning/stack2/sub-{sub}/\",da.from_array(np.array(listData,dtype=\"object\"),chunks=(len(listData))), axis=0)\n",
    "    # np.save(f\"D:\\RnnMachineLearning\\stackData\\sub-{sub}.npy\",np.array(listData))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['001',\n       array([[-0.25932563, -0.25932616, -0.25932607, ..., -0.25932588,\n               -0.25932538, -0.25932538],\n              [-0.00743725, -0.00743928, -0.00744091, ..., -0.00736331,\n               -0.00736335, -0.0073655 ],\n              [-0.00560863, -0.00561094, -0.00561194, ..., -0.00560435,\n               -0.00560297, -0.00560416],\n              ...,\n              [ 0.0039566 ,  0.0039587 ,  0.00395973, ...,  0.00395079,\n                0.00395463,  0.00395432],\n              [-0.00658553, -0.00658869, -0.00659407, ..., -0.006515  ,\n               -0.00656972, -0.00663257],\n              [ 0.00475207,  0.00474994,  0.00474923, ...,  0.00480979,\n                0.00481107,  0.00480794]])                             ,\n       True], dtype=object)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(1091, 3)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrData = np.array(listData,dtype=object)\n",
    "\n",
    "np.save(\"D:\\RnnMachineLearning\\meditation_data.npy\",arrData)\n",
    "arrData.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filterArrtrain = []\n",
    "filterArrtest = []\n",
    "for i in arrData:\n",
    "    if i[0] in (\"001\",\"002\",\"003\"):\n",
    "        filterArrtrain.append(True)\n",
    "        filterArrtest.append(False)\n",
    "    else:\n",
    "        filterArrtest.append(True)\n",
    "        filterArrtrain.append(False)\n",
    "\n",
    "arrtrain = arrData[filterArrtrain]\n",
    "arrtest = arrData[filterArrtest]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "class EegDataSet(Dataset):\n",
    "\n",
    "\tdef __init__(self,dataArray):\n",
    "\t\t#data loading\n",
    "\t\tself.x = torch.from_numpy(np.stack(dataArray[:,1]))\n",
    "\t\tself.labels = torch.from_numpy(dataArray[:,2].astype(\"float32\"))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\t# len(dataset)\n",
    "\t\treturn len(self.labels)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\treturn self.x[idx], self.labels[idx]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "dataArrTrain = EegDataSet(arrtrain)\n",
    "dataArrTest = EegDataSet(arrtest)\n",
    "batch_size=20\n",
    "dlDataArrTrain = DataLoader(dataArrTrain, batch_size=batch_size, shuffle=True)\n",
    "dlDataArrtest = DataLoader(dataArrTest, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# for x,y in dlDataArr:\n",
    "# \tprint(torch.reshape(x,(x.shape[0],1,x.shape[1],x.shape[2])).shape)\n",
    "\n",
    "#[batch_size,1,80,10240]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class Cnn_eeg(Module):\n",
    "    def __init__(self,batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(self.linear_input_neurons(), 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"0:\",x.shape)\n",
    "        x = torch.reshape(x,(x.shape[0],1,x.shape[1],x.shape[2]))\n",
    "        # print(\"1:\",x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # print(\"2:\",x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(\"3:\",x.shape)\n",
    "        x = x.view(x.shape[0], -1) # flatten all dimensions except batch\n",
    "        # print(\"4:\",x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(\"5:\",x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # print(\"6:\",x.shape)\n",
    "        x = self.fc3(x)\n",
    "        # print(\"7:\",x.shape)\n",
    "        return x\n",
    "        # here we apply convolution operations before linear layer, and it returns the 4-dimensional size tensor.\n",
    "    def size_after_relu(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        return x.size()[1:]\n",
    "\n",
    "\n",
    "    # after obtaining the size in above method, we call it and multiply all elements of the returned size.\n",
    "    def linear_input_neurons(self):\n",
    "        size = self.size_after_relu(torch.rand(self.batch_size, 1, 72, 10240))\n",
    "        m = 1\n",
    "        for i in size:\n",
    "            m *= i\n",
    "\n",
    "        return int(m)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "net = Cnn_eeg(batch_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5e99eb2c2674d64917aa16ced9f3272"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0\n",
      "Loss: tensor(0.7051, grad_fn=<NllLossBackward0>)\n",
      "batch: 1\n",
      "Loss: tensor(5.4619, grad_fn=<NllLossBackward0>)\n",
      "batch: 2\n",
      "Loss: tensor(2.2543, grad_fn=<NllLossBackward0>)\n",
      "batch: 3\n",
      "Loss: tensor(0.7488, grad_fn=<NllLossBackward0>)\n",
      "batch: 4\n",
      "Loss: tensor(0.7009, grad_fn=<NllLossBackward0>)\n",
      "batch: 5\n",
      "Loss: tensor(0.7238, grad_fn=<NllLossBackward0>)\n",
      "batch: 6\n",
      "Loss: tensor(0.7252, grad_fn=<NllLossBackward0>)\n",
      "batch: 7\n",
      "Loss: tensor(0.6475, grad_fn=<NllLossBackward0>)\n",
      "batch: 8\n",
      "Loss: tensor(0.7705, grad_fn=<NllLossBackward0>)\n",
      "batch: 9\n",
      "Loss: tensor(0.6962, grad_fn=<NllLossBackward0>)\n",
      "batch: 10\n",
      "Loss: tensor(0.6768, grad_fn=<NllLossBackward0>)\n",
      "batch: 11\n",
      "Loss: tensor(0.7677, grad_fn=<NllLossBackward0>)\n",
      "batch: 12\n",
      "Loss: tensor(0.7033, grad_fn=<NllLossBackward0>)\n",
      "batch: 13\n",
      "Loss: tensor(0.7657, grad_fn=<NllLossBackward0>)\n",
      "batch: 14\n",
      "Loss: tensor(0.6901, grad_fn=<NllLossBackward0>)\n",
      "batch: 15\n",
      "Loss: tensor(0.8596, grad_fn=<NllLossBackward0>)\n",
      "batch: 16\n",
      "Loss: tensor(0.6771, grad_fn=<NllLossBackward0>)\n",
      "batch: 17\n",
      "Loss: tensor(0.6963, grad_fn=<NllLossBackward0>)\n",
      "batch: 18\n",
      "Loss: tensor(0.7247, grad_fn=<NllLossBackward0>)\n",
      "batch: 19\n",
      "Loss: tensor(0.6799, grad_fn=<NllLossBackward0>)\n",
      "batch: 20\n",
      "Loss: tensor(0.7308, grad_fn=<NllLossBackward0>)\n",
      "batch: 21\n",
      "Loss: tensor(0.7748, grad_fn=<NllLossBackward0>)\n",
      "batch: 22\n",
      "Loss: tensor(0.6321, grad_fn=<NllLossBackward0>)\n",
      "batch: 23\n",
      "Loss: tensor(0.7079, grad_fn=<NllLossBackward0>)\n",
      "batch: 24\n",
      "Loss: tensor(0.7253, grad_fn=<NllLossBackward0>)\n",
      "batch: 25\n",
      "Loss: tensor(0.6593, grad_fn=<NllLossBackward0>)\n",
      "batch: 26\n",
      "Loss: tensor(0.7762, grad_fn=<NllLossBackward0>)\n",
      "batch: 27\n",
      "Loss: tensor(0.9789, grad_fn=<NllLossBackward0>)\n",
      "batch: 28\n",
      "Loss: tensor(0.7804, grad_fn=<NllLossBackward0>)\n",
      "batch: 29\n",
      "Loss: tensor(0.7203, grad_fn=<NllLossBackward0>)\n",
      "batch: 30\n",
      "Loss: tensor(0.7323, grad_fn=<NllLossBackward0>)\n",
      "batch: 31\n",
      "Loss: tensor(0.7155, grad_fn=<NllLossBackward0>)\n",
      "batch: 32\n",
      "Loss: tensor(0.6865, grad_fn=<NllLossBackward0>)\n",
      "batch: 33\n",
      "Loss: tensor(0.6965, grad_fn=<NllLossBackward0>)\n",
      "batch: 34\n",
      "Loss: tensor(0.6530, grad_fn=<NllLossBackward0>)\n",
      "batch: 35\n",
      "Loss: tensor(0.8414, grad_fn=<NllLossBackward0>)\n",
      "batch: 36\n",
      "Loss: tensor(0.7167, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f940fbe93c9b42f5a011e503712f6487"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0\n",
      "Loss: tensor(0.6928, grad_fn=<NllLossBackward0>)\n",
      "batch: 1\n",
      "Loss: tensor(0.7723, grad_fn=<NllLossBackward0>)\n",
      "batch: 2\n",
      "Loss: tensor(0.6945, grad_fn=<NllLossBackward0>)\n",
      "batch: 3\n",
      "Loss: tensor(0.6886, grad_fn=<NllLossBackward0>)\n",
      "batch: 4\n",
      "Loss: tensor(0.6742, grad_fn=<NllLossBackward0>)\n",
      "batch: 5\n",
      "Loss: tensor(0.6835, grad_fn=<NllLossBackward0>)\n",
      "batch: 6\n",
      "Loss: tensor(0.7257, grad_fn=<NllLossBackward0>)\n",
      "batch: 7\n",
      "Loss: tensor(0.7117, grad_fn=<NllLossBackward0>)\n",
      "batch: 8\n",
      "Loss: tensor(0.6700, grad_fn=<NllLossBackward0>)\n",
      "batch: 9\n",
      "Loss: tensor(0.6811, grad_fn=<NllLossBackward0>)\n",
      "batch: 10\n",
      "Loss: tensor(0.6592, grad_fn=<NllLossBackward0>)\n",
      "batch: 11\n",
      "Loss: tensor(0.6620, grad_fn=<NllLossBackward0>)\n",
      "batch: 12\n",
      "Loss: tensor(0.6370, grad_fn=<NllLossBackward0>)\n",
      "batch: 13\n",
      "Loss: tensor(0.6542, grad_fn=<NllLossBackward0>)\n",
      "batch: 14\n",
      "Loss: tensor(0.6747, grad_fn=<NllLossBackward0>)\n",
      "batch: 15\n",
      "Loss: tensor(0.7096, grad_fn=<NllLossBackward0>)\n",
      "batch: 16\n",
      "Loss: tensor(0.6289, grad_fn=<NllLossBackward0>)\n",
      "batch: 17\n",
      "Loss: tensor(0.6366, grad_fn=<NllLossBackward0>)\n",
      "batch: 18\n",
      "Loss: tensor(0.5732, grad_fn=<NllLossBackward0>)\n",
      "batch: 19\n",
      "Loss: tensor(0.7485, grad_fn=<NllLossBackward0>)\n",
      "batch: 20\n",
      "Loss: tensor(0.6702, grad_fn=<NllLossBackward0>)\n",
      "batch: 21\n",
      "Loss: tensor(0.6374, grad_fn=<NllLossBackward0>)\n",
      "batch: 22\n",
      "Loss: tensor(0.5893, grad_fn=<NllLossBackward0>)\n",
      "batch: 23\n",
      "Loss: tensor(0.6483, grad_fn=<NllLossBackward0>)\n",
      "batch: 24\n",
      "Loss: tensor(0.5567, grad_fn=<NllLossBackward0>)\n",
      "batch: 25\n",
      "Loss: tensor(0.6390, grad_fn=<NllLossBackward0>)\n",
      "batch: 26\n",
      "Loss: tensor(0.5483, grad_fn=<NllLossBackward0>)\n",
      "batch: 27\n",
      "Loss: tensor(0.5682, grad_fn=<NllLossBackward0>)\n",
      "batch: 28\n",
      "Loss: tensor(0.4919, grad_fn=<NllLossBackward0>)\n",
      "batch: 29\n",
      "Loss: tensor(0.5205, grad_fn=<NllLossBackward0>)\n",
      "batch: 30\n",
      "Loss: tensor(0.6161, grad_fn=<NllLossBackward0>)\n",
      "batch: 31\n",
      "Loss: tensor(0.5835, grad_fn=<NllLossBackward0>)\n",
      "batch: 32\n",
      "Loss: tensor(0.6016, grad_fn=<NllLossBackward0>)\n",
      "batch: 33\n",
      "Loss: tensor(0.5356, grad_fn=<NllLossBackward0>)\n",
      "batch: 34\n",
      "Loss: tensor(0.5107, grad_fn=<NllLossBackward0>)\n",
      "batch: 35\n",
      "Loss: tensor(0.6148, grad_fn=<NllLossBackward0>)\n",
      "batch: 36\n",
      "Loss: tensor(0.5602, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0dc9550f6ea64489a899be47c86dbe1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0\n",
      "Loss: tensor(0.5437, grad_fn=<NllLossBackward0>)\n",
      "batch: 1\n",
      "Loss: tensor(0.5357, grad_fn=<NllLossBackward0>)\n",
      "batch: 2\n",
      "Loss: tensor(0.4336, grad_fn=<NllLossBackward0>)\n",
      "batch: 3\n",
      "Loss: tensor(0.4952, grad_fn=<NllLossBackward0>)\n",
      "batch: 4\n",
      "Loss: tensor(0.4601, grad_fn=<NllLossBackward0>)\n",
      "batch: 5\n",
      "Loss: tensor(0.5368, grad_fn=<NllLossBackward0>)\n",
      "batch: 6\n",
      "Loss: tensor(0.4870, grad_fn=<NllLossBackward0>)\n",
      "batch: 7\n",
      "Loss: tensor(0.6968, grad_fn=<NllLossBackward0>)\n",
      "batch: 8\n",
      "Loss: tensor(0.7188, grad_fn=<NllLossBackward0>)\n",
      "batch: 9\n",
      "Loss: tensor(0.5063, grad_fn=<NllLossBackward0>)\n",
      "batch: 10\n",
      "Loss: tensor(0.4102, grad_fn=<NllLossBackward0>)\n",
      "batch: 11\n",
      "Loss: tensor(0.4460, grad_fn=<NllLossBackward0>)\n",
      "batch: 12\n",
      "Loss: tensor(0.3660, grad_fn=<NllLossBackward0>)\n",
      "batch: 13\n",
      "Loss: tensor(0.7366, grad_fn=<NllLossBackward0>)\n",
      "batch: 14\n",
      "Loss: tensor(0.4685, grad_fn=<NllLossBackward0>)\n",
      "batch: 15\n",
      "Loss: tensor(0.6097, grad_fn=<NllLossBackward0>)\n",
      "batch: 16\n",
      "Loss: tensor(0.4730, grad_fn=<NllLossBackward0>)\n",
      "batch: 17\n",
      "Loss: tensor(0.3978, grad_fn=<NllLossBackward0>)\n",
      "batch: 18\n",
      "Loss: tensor(0.9150, grad_fn=<NllLossBackward0>)\n",
      "batch: 19\n",
      "Loss: tensor(0.4689, grad_fn=<NllLossBackward0>)\n",
      "batch: 20\n",
      "Loss: tensor(0.4830, grad_fn=<NllLossBackward0>)\n",
      "batch: 21\n",
      "Loss: tensor(0.5553, grad_fn=<NllLossBackward0>)\n",
      "batch: 22\n",
      "Loss: tensor(0.4809, grad_fn=<NllLossBackward0>)\n",
      "batch: 23\n",
      "Loss: tensor(0.5355, grad_fn=<NllLossBackward0>)\n",
      "batch: 24\n",
      "Loss: tensor(0.5765, grad_fn=<NllLossBackward0>)\n",
      "batch: 25\n",
      "Loss: tensor(0.5437, grad_fn=<NllLossBackward0>)\n",
      "batch: 26\n",
      "Loss: tensor(0.4517, grad_fn=<NllLossBackward0>)\n",
      "batch: 27\n",
      "Loss: tensor(0.4926, grad_fn=<NllLossBackward0>)\n",
      "batch: 28\n",
      "Loss: tensor(0.5724, grad_fn=<NllLossBackward0>)\n",
      "batch: 29\n",
      "Loss: tensor(0.4479, grad_fn=<NllLossBackward0>)\n",
      "batch: 30\n",
      "Loss: tensor(0.5350, grad_fn=<NllLossBackward0>)\n",
      "batch: 31\n",
      "Loss: tensor(0.3353, grad_fn=<NllLossBackward0>)\n",
      "batch: 32\n",
      "Loss: tensor(0.3752, grad_fn=<NllLossBackward0>)\n",
      "batch: 33\n",
      "Loss: tensor(0.5834, grad_fn=<NllLossBackward0>)\n",
      "batch: 34\n",
      "Loss: tensor(0.4477, grad_fn=<NllLossBackward0>)\n",
      "batch: 35\n",
      "Loss: tensor(0.5752, grad_fn=<NllLossBackward0>)\n",
      "batch: 36\n",
      "Loss: tensor(0.2623, grad_fn=<NllLossBackward0>)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "\n",
    "    for i, data in tqdm(enumerate(dlDataArrTrain, 0)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(torch.float32),data[1].to(torch.int64)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        # print(outputs)\n",
    "        # print(outputs.shape)\n",
    "        # print(outputs.dtype)\n",
    "        # print(labels.shape)\n",
    "        # print(labels.dtype)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        print(\"batch:\",i)\n",
    "        print(\"Loss:\",loss)\n",
    "\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f3a3aef5faa48298cc4a2dd33204e23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0\n",
      "Loss: tensor(0.3868, grad_fn=<NllLossBackward0>)\n",
      "batch: 1\n",
      "Loss: tensor(0.3688, grad_fn=<NllLossBackward0>)\n",
      "batch: 2\n",
      "Loss: tensor(0.4335, grad_fn=<NllLossBackward0>)\n",
      "batch: 3\n",
      "Loss: tensor(0.4581, grad_fn=<NllLossBackward0>)\n",
      "batch: 4\n",
      "Loss: tensor(0.4408, grad_fn=<NllLossBackward0>)\n",
      "batch: 5\n",
      "Loss: tensor(0.5864, grad_fn=<NllLossBackward0>)\n",
      "batch: 6\n",
      "Loss: tensor(0.4602, grad_fn=<NllLossBackward0>)\n",
      "batch: 7\n",
      "Loss: tensor(0.4249, grad_fn=<NllLossBackward0>)\n",
      "batch: 8\n",
      "Loss: tensor(0.4342, grad_fn=<NllLossBackward0>)\n",
      "batch: 9\n",
      "Loss: tensor(0.4479, grad_fn=<NllLossBackward0>)\n",
      "batch: 10\n",
      "Loss: tensor(0.4878, grad_fn=<NllLossBackward0>)\n",
      "batch: 11\n",
      "Loss: tensor(0.4780, grad_fn=<NllLossBackward0>)\n",
      "batch: 12\n",
      "Loss: tensor(0.4696, grad_fn=<NllLossBackward0>)\n",
      "batch: 13\n",
      "Loss: tensor(0.5608, grad_fn=<NllLossBackward0>)\n",
      "batch: 14\n",
      "Loss: tensor(0.3705, grad_fn=<NllLossBackward0>)\n",
      "batch: 15\n",
      "Loss: tensor(0.4265, grad_fn=<NllLossBackward0>)\n",
      "batch: 16\n",
      "Loss: tensor(0.3796, grad_fn=<NllLossBackward0>)\n",
      "batch: 17\n",
      "Loss: tensor(0.4314, grad_fn=<NllLossBackward0>)\n",
      "batch: 18\n",
      "Loss: tensor(0.4879, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i, data in tqdm(enumerate(dlDataArrtest, 0)):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data[0].to(torch.float32),data[1].to(torch.int64)\n",
    "\n",
    "\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    # print(outputs)\n",
    "    # print(outputs.shape)\n",
    "    # print(outputs.dtype)\n",
    "    # print(labels.shape)\n",
    "    # print(labels.dtype)\n",
    "    loss = criterion(outputs, labels)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # print statistics\n",
    "    print(\"batch:\",i)\n",
    "    print(\"Loss:\",loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# switch off autograd for evaluation\n",
    "lossFinale= sum(losses)/len(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4491594888662037"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossFinale"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}