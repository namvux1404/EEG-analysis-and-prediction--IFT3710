{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch import nn\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "dataList = [da.from_npy_stack(f\"D:/RnnMachineLearning/stack2/sub-{str(sub).zfill(3)}/\") for sub in range(1,6)]\n",
    "# data = np.load('D:\\RnnMachineLearning\\meditation_data.npy',allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Array can't be memory-mapped: Python objects in dtype.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [68]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m data \u001B[38;5;241m=\u001B[39m da\u001B[38;5;241m.\u001B[39mconcatenate(dataList, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      2\u001B[0m a \u001B[38;5;241m=\u001B[39mdata[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m----> 3\u001B[0m \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_chunk_sizes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\array\\core.py:1446\u001B[0m, in \u001B[0;36mArray.compute_chunk_sizes\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1441\u001B[0m     c\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mtuple\u001B[39m(chunk_shapes[s]))\n\u001B[0;32m   1443\u001B[0m \u001B[38;5;66;03m# `map_blocks` assigns numpy dtypes\u001B[39;00m\n\u001B[0;32m   1444\u001B[0m \u001B[38;5;66;03m# cast chunk dimensions back to python int before returning\u001B[39;00m\n\u001B[0;32m   1445\u001B[0m x\u001B[38;5;241m.\u001B[39m_chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\n\u001B[1;32m-> 1446\u001B[0m     \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mint\u001B[39m(chunk) \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunks) \u001B[38;5;28;01mfor\u001B[39;00m chunks \u001B[38;5;129;01min\u001B[39;00m \u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1447\u001B[0m )\n\u001B[0;32m   1448\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\base.py:575\u001B[0m, in \u001B[0;36mcompute\u001B[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001B[0m\n\u001B[0;32m    572\u001B[0m     keys\u001B[38;5;241m.\u001B[39mappend(x\u001B[38;5;241m.\u001B[39m__dask_keys__())\n\u001B[0;32m    573\u001B[0m     postcomputes\u001B[38;5;241m.\u001B[39mappend(x\u001B[38;5;241m.\u001B[39m__dask_postcompute__())\n\u001B[1;32m--> 575\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mschedule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdsk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    576\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m repack([f(r, \u001B[38;5;241m*\u001B[39ma) \u001B[38;5;28;01mfor\u001B[39;00m r, (f, a) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(results, postcomputes)])\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\threaded.py:81\u001B[0m, in \u001B[0;36mget\u001B[1;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001B[0m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pool, multiprocessing\u001B[38;5;241m.\u001B[39mpool\u001B[38;5;241m.\u001B[39mPool):\n\u001B[0;32m     79\u001B[0m         pool \u001B[38;5;241m=\u001B[39m MultiprocessingPoolExecutor(pool)\n\u001B[1;32m---> 81\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mget_async\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_max_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdsk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43mget_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_thread_get_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpack_exception\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpack_exception\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;66;03m# Cleanup pools associated to dead threads\u001B[39;00m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pools_lock:\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\local.py:508\u001B[0m, in \u001B[0;36mget_async\u001B[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001B[0m\n\u001B[0;32m    506\u001B[0m         _execute_task(task, data)  \u001B[38;5;66;03m# Re-execute locally\u001B[39;00m\n\u001B[0;32m    507\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 508\u001B[0m         \u001B[43mraise_exception\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    509\u001B[0m res, worker_id \u001B[38;5;241m=\u001B[39m loads(res_info)\n\u001B[0;32m    510\u001B[0m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache\u001B[39m\u001B[38;5;124m\"\u001B[39m][key] \u001B[38;5;241m=\u001B[39m res\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\local.py:316\u001B[0m, in \u001B[0;36mreraise\u001B[1;34m(exc, tb)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exc\u001B[38;5;241m.\u001B[39m__traceback__ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tb:\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\u001B[38;5;241m.\u001B[39mwith_traceback(tb)\n\u001B[1;32m--> 316\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\local.py:221\u001B[0m, in \u001B[0;36mexecute_task\u001B[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001B[0m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    220\u001B[0m     task, data \u001B[38;5;241m=\u001B[39m loads(task_info)\n\u001B[1;32m--> 221\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_execute_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    222\u001B[0m     \u001B[38;5;28mid\u001B[39m \u001B[38;5;241m=\u001B[39m get_id()\n\u001B[0;32m    223\u001B[0m     result \u001B[38;5;241m=\u001B[39m dumps((result, \u001B[38;5;28mid\u001B[39m))\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\core.py:119\u001B[0m, in \u001B[0;36m_execute_task\u001B[1;34m(arg, cache, dsk)\u001B[0m\n\u001B[0;32m    115\u001B[0m     func, args \u001B[38;5;241m=\u001B[39m arg[\u001B[38;5;241m0\u001B[39m], arg[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001B[39;00m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;66;03m# temporaries by their reference count and can execute certain\u001B[39;00m\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# operations in-place.\u001B[39;00m\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_execute_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ishashable(arg):\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arg\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\core.py:119\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    115\u001B[0m     func, args \u001B[38;5;241m=\u001B[39m arg[\u001B[38;5;241m0\u001B[39m], arg[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001B[39;00m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;66;03m# temporaries by their reference count and can execute certain\u001B[39;00m\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# operations in-place.\u001B[39;00m\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m(\u001B[43m_execute_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m args))\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ishashable(arg):\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arg\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\core.py:119\u001B[0m, in \u001B[0;36m_execute_task\u001B[1;34m(arg, cache, dsk)\u001B[0m\n\u001B[0;32m    115\u001B[0m     func, args \u001B[38;5;241m=\u001B[39m arg[\u001B[38;5;241m0\u001B[39m], arg[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001B[39;00m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;66;03m# temporaries by their reference count and can execute certain\u001B[39;00m\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# operations in-place.\u001B[39;00m\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_execute_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ishashable(arg):\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arg\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\core.py:119\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    115\u001B[0m     func, args \u001B[38;5;241m=\u001B[39m arg[\u001B[38;5;241m0\u001B[39m], arg[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001B[39;00m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;66;03m# temporaries by their reference count and can execute certain\u001B[39;00m\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# operations in-place.\u001B[39;00m\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m(\u001B[43m_execute_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m args))\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ishashable(arg):\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arg\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\core.py:119\u001B[0m, in \u001B[0;36m_execute_task\u001B[1;34m(arg, cache, dsk)\u001B[0m\n\u001B[0;32m    115\u001B[0m     func, args \u001B[38;5;241m=\u001B[39m arg[\u001B[38;5;241m0\u001B[39m], arg[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001B[39;00m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;66;03m# temporaries by their reference count and can execute certain\u001B[39;00m\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# operations in-place.\u001B[39;00m\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_execute_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ishashable(arg):\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arg\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\core.py:119\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    115\u001B[0m     func, args \u001B[38;5;241m=\u001B[39m arg[\u001B[38;5;241m0\u001B[39m], arg[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001B[39;00m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;66;03m# temporaries by their reference count and can execute certain\u001B[39;00m\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# operations in-place.\u001B[39;00m\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m(\u001B[43m_execute_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m args))\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ishashable(arg):\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arg\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\core.py:119\u001B[0m, in \u001B[0;36m_execute_task\u001B[1;34m(arg, cache, dsk)\u001B[0m\n\u001B[0;32m    115\u001B[0m     func, args \u001B[38;5;241m=\u001B[39m arg[\u001B[38;5;241m0\u001B[39m], arg[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001B[39;00m\n\u001B[0;32m    117\u001B[0m     \u001B[38;5;66;03m# temporaries by their reference count and can execute certain\u001B[39;00m\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;66;03m# operations in-place.\u001B[39;00m\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_execute_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ishashable(arg):\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arg\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\numpy\\lib\\npyio.py:428\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001B[0m\n\u001B[0;32m    425\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m magic \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m.\u001B[39mMAGIC_PREFIX:\n\u001B[0;32m    426\u001B[0m     \u001B[38;5;66;03m# .npy file\u001B[39;00m\n\u001B[0;32m    427\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mmap_mode:\n\u001B[1;32m--> 428\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_memmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmmap_mode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    429\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    430\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m.\u001B[39mread_array(fid, allow_pickle\u001B[38;5;241m=\u001B[39mallow_pickle,\n\u001B[0;32m    431\u001B[0m                                  pickle_kwargs\u001B[38;5;241m=\u001B[39mpickle_kwargs)\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\numpy\\lib\\format.py:873\u001B[0m, in \u001B[0;36mopen_memmap\u001B[1;34m(filename, mode, dtype, shape, fortran_order, version)\u001B[0m\n\u001B[0;32m    871\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m dtype\u001B[38;5;241m.\u001B[39mhasobject:\n\u001B[0;32m    872\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArray can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt be memory-mapped: Python objects in dtype.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 873\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    874\u001B[0m         offset \u001B[38;5;241m=\u001B[39m fp\u001B[38;5;241m.\u001B[39mtell()\n\u001B[0;32m    876\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fortran_order:\n",
      "\u001B[1;31mValueError\u001B[0m: Array can't be memory-mapped: Python objects in dtype."
     ]
    }
   ],
   "source": [
    "data = da.concatenate(dataList, axis=0)\n",
    "a =data[0]\n",
    "a.compute_chunk_sizes()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "filterArrtrain = []\n",
    "filterArrtest = []\n",
    "for i in data:\n",
    "    if i[0] in (\"001\",\"002\",\"003\"):\n",
    "        filterArrtrain.append(True)\n",
    "        filterArrtest.append(False)\n",
    "    else:\n",
    "        filterArrtest.append(True)\n",
    "        filterArrtrain.append(False)\n",
    "\n",
    "arrtrain = data[filterArrtrain]\n",
    "arrtest = data[filterArrtest]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class EegDataSet(Dataset):\n",
    "\n",
    "\tdef __init__(self,dataArray):\n",
    "\t\t#data loading\n",
    "\t\tself.x = torch.from_numpy(np.stack(dataArray[:,1]))\n",
    "\t\tself.labels = torch.from_numpy(dataArray[:,2].astype(\"float32\"))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\t# len(dataset)\n",
    "\t\treturn len(self.labels)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\treturn self.x[idx], self.labels[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "hidden_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 1\n",
    "batch_size = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 72\n",
    "sequence_length = 10240\n",
    "num_layers = 2\n",
    "\n",
    "dataArrTrain = EegDataSet(arrtrain)\n",
    "dataArrTest = EegDataSet(arrtest)\n",
    "\n",
    "dlDataArrTrain = DataLoader(dataArrTrain, batch_size=batch_size, shuffle=True)\n",
    "dlDataArrtest = DataLoader(dataArrTest, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# NETWORK\n",
    "\n",
    "# Vanilla RNN\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        # x -> (batch_size, sequence_length, input_size)\n",
    "\n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[2],x.shape[1]))\n",
    "        # print(x.shape)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # print(x.shape)\n",
    "        # print(h0.shape)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # out -> (batch_size, sequence_length, hidden_size)\n",
    "        # out -> (N, 129, 128) ->> NOTE: CHANGE SEQUENCE_LENGTH AS 750 LATER (TRANPOSE THE TENSOR)\n",
    "        out = out[:, -1, :]\n",
    "        # out -> (N, 128)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/37], Loss: 0.6758\n",
      "Epoch [1/1], Step [2/37], Loss: 0.6909\n",
      "Epoch [1/1], Step [3/37], Loss: 0.8045\n",
      "Epoch [1/1], Step [4/37], Loss: 0.7722\n",
      "Epoch [1/1], Step [5/37], Loss: 0.7057\n",
      "Epoch [1/1], Step [6/37], Loss: 0.6930\n",
      "Epoch [1/1], Step [7/37], Loss: 0.6907\n",
      "Epoch [1/1], Step [8/37], Loss: 0.6995\n",
      "Epoch [1/1], Step [9/37], Loss: 0.6864\n",
      "Epoch [1/1], Step [10/37], Loss: 0.6921\n",
      "Epoch [1/1], Step [11/37], Loss: 0.6836\n",
      "Epoch [1/1], Step [12/37], Loss: 0.7003\n",
      "Epoch [1/1], Step [13/37], Loss: 0.7089\n",
      "Epoch [1/1], Step [14/37], Loss: 0.6868\n",
      "Epoch [1/1], Step [15/37], Loss: 0.6918\n",
      "Epoch [1/1], Step [16/37], Loss: 0.6943\n",
      "Epoch [1/1], Step [17/37], Loss: 0.6896\n",
      "Epoch [1/1], Step [18/37], Loss: 0.6896\n",
      "Epoch [1/1], Step [19/37], Loss: 0.6908\n",
      "Epoch [1/1], Step [20/37], Loss: 0.6928\n",
      "Epoch [1/1], Step [21/37], Loss: 0.6883\n",
      "Epoch [1/1], Step [22/37], Loss: 0.6860\n",
      "Epoch [1/1], Step [23/37], Loss: 0.6902\n",
      "Epoch [1/1], Step [24/37], Loss: 0.6877\n",
      "Epoch [1/1], Step [25/37], Loss: 0.6856\n",
      "Epoch [1/1], Step [26/37], Loss: 0.6805\n",
      "Epoch [1/1], Step [27/37], Loss: 0.6857\n",
      "Epoch [1/1], Step [28/37], Loss: 0.6527\n",
      "Epoch [1/1], Step [29/37], Loss: 0.6856\n",
      "Epoch [1/1], Step [30/37], Loss: 0.6792\n",
      "Epoch [1/1], Step [31/37], Loss: 0.6859\n",
      "Epoch [1/1], Step [32/37], Loss: 0.5642\n",
      "Epoch [1/1], Step [33/37], Loss: 0.6528\n",
      "Epoch [1/1], Step [34/37], Loss: 0.4821\n",
      "Epoch [1/1], Step [35/37], Loss: 0.8289\n",
      "Epoch [1/1], Step [36/37], Loss: 1.2028\n",
      "Epoch [1/1], Step [37/37], Loss: 0.6238\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(dlDataArrTrain)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data_b in enumerate(dlDataArrTrain):\n",
    "\n",
    "        inputs, labels = data_b[0].to(torch.float32),data_b[1].to(torch.int64)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0]) tensor([1, 0, 1, 0, 1, 1, 1])\n",
      "Accuracy of the network: 32.69754768392371 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data_b in dlDataArrtest:\n",
    "        inputs, labels = data_b[0].to(torch.float32),data_b[1].to(torch.int64)\n",
    "        outputs = model(inputs)\n",
    "        # max returns (value ,index)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        #print(predicted, labels)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}