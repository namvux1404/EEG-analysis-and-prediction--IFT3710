{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch import nn\n",
    "import dask.array as da\n",
    "from time import time\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<KeysViewHDF5 ['sub-001', 'sub-002', 'sub-003', 'sub-004', 'sub-005', 'sub-006', 'sub-007', 'sub-008', 'sub-009', 'sub-010', 'sub-011', 'sub-012', 'sub-013', 'sub-014', 'sub-015', 'sub-016', 'sub-017', 'sub-018', 'sub-019', 'sub-020', 'sub-021', 'sub-022', 'sub-023', 'sub-024', 'sub-025', 'sub-026', 'sub-027', 'sub-028', 'sub-029', 'sub-030', 'sub-031', 'sub-032', 'sub-033', 'sub-034', 'sub-035', 'sub-036', 'sub-037', 'sub-038', 'sub-039', 'sub-040', 'sub-041', 'sub-042', 'sub-043', 'sub-044', 'sub-045', 'sub-046', 'sub-047', 'sub-048', 'sub-049', 'sub-050', 'sub-051', 'sub-052', 'sub-053', 'sub-054', 'sub-055', 'sub-056', 'sub-057', 'sub-058', 'sub-059', 'sub-060', 'sub-061', 'sub-062', 'sub-063', 'sub-064', 'sub-065', 'sub-066', 'sub-067', 'sub-068', 'sub-069', 'sub-070', 'sub-071', 'sub-072', 'sub-073', 'sub-074', 'sub-075', 'sub-076', 'sub-077', 'sub-078', 'sub-079', 'sub-080', 'sub-081', 'sub-082', 'sub-083', 'sub-084', 'sub-085', 'sub-086', 'sub-087', 'sub-088', 'sub-089', 'sub-090', 'sub-091', 'sub-092', 'sub-093', 'sub-094', 'sub-095', 'sub-096', 'sub-097', 'sub-098']>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "h5file = \"D:\\RnnMachineLearning\\meditationData.hdf5\"\n",
    "f = h5py.File(h5file, 'r')\n",
    "f.keys()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def databykeys(hdfFile,hdfkeys):\n",
    "    DataList = [da.from_array(hdfFile[i][j])for i in hdfkeys for j in hdfFile[i].keys() if \"data\" in j]\n",
    "    data = da.concatenate(DataList, axis=0)\n",
    "\n",
    "    LabelsList = [da.from_array(hdfFile[i][j])for i in hdfkeys for j in hdfFile[i].keys() if \"labels\" in j]\n",
    "    labels = da.concatenate(LabelsList, axis=0)\n",
    "\n",
    "    IdsList = [da.from_array(hdfFile[i][j])for i in hdfkeys for j in hdfFile[i].keys() if \"ids\" in j]\n",
    "    ids = da.concatenate(IdsList, axis=0)\n",
    "\n",
    "    return data,labels,ids\n",
    "\n",
    "def train_test_split(hdfFile,dataSample=1,testratio=0.2,random_seed=True,random_seed_value =42):\n",
    "    numPts = int(98*dataSample)\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed_value)\n",
    "        random.seed(random_seed_value)\n",
    "\n",
    "    myset = set(np.random.choice(range(1,99),numPts,replace=False))\n",
    "\n",
    "    testIds = random.sample(myset, int(testratio*98))\n",
    "    trainIds = myset -set(testIds)\n",
    "\n",
    "    trainKeys = [i for i in f.keys() if int(i[-3:]) in trainIds]\n",
    "    testKeys = [i for i in f.keys() if int(i[-3:]) in testIds]\n",
    "\n",
    "    trainData = databykeys(hdfFile,trainKeys)\n",
    "    testData = databykeys(hdfFile,testKeys)\n",
    "\n",
    "    return trainData,testData\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "class EegDataSet(Dataset):\n",
    "\n",
    "\tdef __init__(self,dataArray):\n",
    "\t\t#data loading\n",
    "\t\tself.x = torch.from_numpy(np.stack(dataArray[:,1]))\n",
    "\t\tself.labels = torch.from_numpy(dataArray[:,2].astype(\"float32\"))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\t# len(dataset)\n",
    "\t\treturn len(self.labels)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\treturn self.x[idx], self.labels[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "class EegDataSetDask(Dataset):\n",
    "    def __init__(self,dataArray):\n",
    "        #data loading\n",
    "        self.x = dataArray[0]\n",
    "        self.labels = dataArray[1]\n",
    "        self.ids = dataArray[2]\n",
    "\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.x[idx].compute()), torch.from_numpy(self.labels[idx].compute())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "class Cnn_eeg(nn.Module):\n",
    "    def __init__(self,batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(self.linear_input_neurons(), 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"0:\",x.shape)\n",
    "        x = torch.reshape(x,(x.shape[0],1,x.shape[1],x.shape[2]))\n",
    "        # print(\"1:\",x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # print(\"2:\",x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(\"3:\",x.shape)\n",
    "        x = x.view(x.shape[0], -1) # flatten all dimensions except batch\n",
    "        # print(\"4:\",x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(\"5:\",x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # print(\"6:\",x.shape)\n",
    "        x = self.fc3(x)\n",
    "        # print(\"7:\",x.shape)\n",
    "        return x\n",
    "        # here we apply convolution operations before linear layer, and it returns the 4-dimensional size tensor.\n",
    "    def size_after_relu(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        return x.size()[1:]\n",
    "\n",
    "\n",
    "    # after obtaining the size in above method, we call it and multiply all elements of the returned size.\n",
    "    def linear_input_neurons(self):\n",
    "        size = self.size_after_relu(torch.rand(self.batch_size, 1, 72, 10240))\n",
    "        m = 1\n",
    "        for i in size:\n",
    "            m *= i\n",
    "\n",
    "        return int(m)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# NETWORK\n",
    "\n",
    "# Vanilla RNN\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        # x -> (batch_size, sequence_length, input_size)\n",
    "\n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[2],x.shape[1]))\n",
    "        # print(x.shape)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # print(x.shape)\n",
    "        # print(h0.shape)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # out -> (batch_size, sequence_length, hidden_size)\n",
    "        # out -> (N, 129, 128) ->> NOTE: CHANGE SEQUENCE_LENGTH AS 750 LATER (TRANPOSE THE TENSOR)\n",
    "        out = out[:, -1, :]\n",
    "        # out -> (N, 128)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "class GRUmodel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers,num_classes):\n",
    "        super(GRUmodel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[2],x.shape[1]))\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim,n_layers,num_classes):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[2],x.shape[1]))\n",
    "        out, h = self.lstm(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData,testData = train_test_split(f,dataSample=0.25)\n",
    "torch.cuda.is_available()\n",
    "# torch.version.cuda()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CNN testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "dataArrTrain = EegDataSetDask(trainData)\n",
    "dataArrTest = EegDataSetDask(testData)\n",
    "\n",
    "dlDataArrTrain = DataLoader(dataArrTrain, batch_size=batch_size, shuffle=True,num_workers=0,pin_memory=False)\n",
    "dlDataArrtest = DataLoader(dataArrTest, batch_size=batch_size, shuffle=True,num_workers=0,pin_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "net = Cnn_eeg(batch_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73580e6b59fb4272be2ae4f2817c90c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/111], Loss: 0.6980, Time : 7.66520357131958\n",
      "Epoch [1/1], Step [2/111], Loss: 2.4366, Time : 8.322979927062988\n",
      "Epoch [1/1], Step [3/111], Loss: 0.9207, Time : 8.125818967819214\n",
      "Epoch [1/1], Step [4/111], Loss: 0.8140, Time : 8.398743391036987\n",
      "Epoch [1/1], Step [5/111], Loss: 0.7930, Time : 7.0264177322387695\n",
      "Epoch [1/1], Step [6/111], Loss: 0.7144, Time : 7.162515878677368\n",
      "Epoch [1/1], Step [7/111], Loss: 0.7406, Time : 7.730671167373657\n",
      "Epoch [1/1], Step [8/111], Loss: 0.7193, Time : 8.62544298171997\n",
      "Epoch [1/1], Step [9/111], Loss: 0.7261, Time : 8.230851173400879\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [50]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m scaler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mGradScaler()\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m):  \u001B[38;5;66;03m# loop over the dataset multiple times\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, data_b \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(dlDataArrTrain, \u001B[38;5;241m0\u001B[39m)):\n\u001B[0;32m      8\u001B[0m         start \u001B[38;5;241m=\u001B[39m time()\n\u001B[0;32m      9\u001B[0m         inputs, labels \u001B[38;5;241m=\u001B[39m data_b[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat32),data_b[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mint64)\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\tqdm\\notebook.py:258\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    257\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[1;32m--> 258\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m    261\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\tqdm\\std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    569\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 570\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    572\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Input \u001B[1;32mIn [42]\u001B[0m, in \u001B[0;36mEegDataSetDask.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m---> 13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m), torch\u001B[38;5;241m.\u001B[39mfrom_numpy(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels[idx]\u001B[38;5;241m.\u001B[39mcompute())\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\base.py:292\u001B[0m, in \u001B[0;36mDaskMethodsMixin.compute\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    268\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    269\u001B[0m     \u001B[38;5;124;03m\"\"\"Compute this dask collection\u001B[39;00m\n\u001B[0;32m    270\u001B[0m \n\u001B[0;32m    271\u001B[0m \u001B[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m    dask.base.compute\u001B[39;00m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 292\u001B[0m     (result,) \u001B[38;5;241m=\u001B[39m \u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraverse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\base.py:575\u001B[0m, in \u001B[0;36mcompute\u001B[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001B[0m\n\u001B[0;32m    572\u001B[0m     keys\u001B[38;5;241m.\u001B[39mappend(x\u001B[38;5;241m.\u001B[39m__dask_keys__())\n\u001B[0;32m    573\u001B[0m     postcomputes\u001B[38;5;241m.\u001B[39mappend(x\u001B[38;5;241m.\u001B[39m__dask_postcompute__())\n\u001B[1;32m--> 575\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mschedule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdsk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    576\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m repack([f(r, \u001B[38;5;241m*\u001B[39ma) \u001B[38;5;28;01mfor\u001B[39;00m r, (f, a) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(results, postcomputes)])\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\threaded.py:81\u001B[0m, in \u001B[0;36mget\u001B[1;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001B[0m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pool, multiprocessing\u001B[38;5;241m.\u001B[39mpool\u001B[38;5;241m.\u001B[39mPool):\n\u001B[0;32m     79\u001B[0m         pool \u001B[38;5;241m=\u001B[39m MultiprocessingPoolExecutor(pool)\n\u001B[1;32m---> 81\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mget_async\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_max_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdsk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m    \u001B[49m\u001B[43mget_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_thread_get_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpack_exception\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpack_exception\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;66;03m# Cleanup pools associated to dead threads\u001B[39;00m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pools_lock:\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\local.py:497\u001B[0m, in \u001B[0;36mget_async\u001B[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001B[0m\n\u001B[0;32m    495\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwaiting\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mready\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrunning\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    496\u001B[0m     fire_tasks(chunksize)\n\u001B[1;32m--> 497\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m key, res_info, failed \u001B[38;5;129;01min\u001B[39;00m \u001B[43mqueue_get\u001B[49m\u001B[43m(\u001B[49m\u001B[43mqueue\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mresult():\n\u001B[0;32m    498\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m failed:\n\u001B[0;32m    499\u001B[0m             exc, tb \u001B[38;5;241m=\u001B[39m loads(res_info)\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\dask\\local.py:127\u001B[0m, in \u001B[0;36mqueue_get\u001B[1;34m(q)\u001B[0m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    126\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 127\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Empty:\n\u001B[0;32m    129\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\live_\\appdata\\local\\programs\\python\\python38\\lib\\queue.py:179\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    177\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m remaining \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[0;32m    178\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m--> 179\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnot_empty\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mremaining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    180\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get()\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnot_full\u001B[38;5;241m.\u001B[39mnotify()\n",
      "File \u001B[1;32mc:\\users\\live_\\appdata\\local\\programs\\python\\python38\\lib\\threading.py:306\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    305\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 306\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    307\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    308\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model CNN\n",
    "n_total_steps = len(dlDataArrTrain)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "\n",
    "    for i, data_b in tqdm(enumerate(dlDataArrTrain, 0)):\n",
    "        start = time()\n",
    "        inputs, labels = data_b[0].to(torch.float32),data_b[1].to(torch.int64)\n",
    "\n",
    "        # Forward pass\n",
    "        # Runs the forward pass with autocasting.\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        for param in net.parameters():\n",
    "            param.grad = None\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        end=time()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}, Time : {end-start}')\n",
    "\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "torch.save(net, 'cnn.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data_b in dlDataArrtest:\n",
    "        inputs, labels = data_b[0].to(torch.float32),data_b[1].to(torch.int64)\n",
    "        outputs = net(inputs)\n",
    "        # max returns (value ,index)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        #print(predicted, labels)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GRU testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size = 72\n",
    "sequence_length = 10240\n",
    "num_classes = 2\n",
    "# HYPERPARAMETERS\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "dataArrTrain = EegDataSetDask(trainData)\n",
    "dataArrTest = EegDataSetDask(testData)\n",
    "\n",
    "dlDataArrTrain = DataLoader(dataArrTrain, batch_size=batch_size, shuffle=True,num_workers=0,pin_memory=False)\n",
    "dlDataArrtest = DataLoader(dataArrTest, batch_size=batch_size, shuffle=True,num_workers=0,pin_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = GRUmodel(input_size, hidden_size, num_layers, num_classes).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\live_\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "C:\\Users\\live_\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/596], Loss: 0.6919, Time : 40.33398199081421\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mparameters():\n\u001B[0;32m     19\u001B[0m     param\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n\u001B[0;32m     22\u001B[0m scaler\u001B[38;5;241m.\u001B[39mupdate()\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\_tensor.py:363\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    354\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    355\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    356\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    357\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    361\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[0;32m    362\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[1;32m--> 363\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(dlDataArrTrain)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "h = model.init_hidden(batch_size)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i, data_b in enumerate(dlDataArrTrain):\n",
    "        start = time()\n",
    "        inputs, labels = data_b[0].to(torch.float32),data_b[1].to(torch.int64)\n",
    "        h = h.data\n",
    "        # Forward pass\n",
    "        # Runs the forward pass with autocasting.\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs,h = model(inputs,h)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        end=time()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}, Time : {end-start}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(net, 'gru.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'collections.OrderedDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data_b \u001B[38;5;129;01min\u001B[39;00m dlDataArrtest:\n\u001B[0;32m      8\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m data_b[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat32),data_b[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mint64)\n\u001B[1;32m----> 9\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# max returns (value ,index)\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     _, predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'collections.OrderedDict' object is not callable"
     ]
    }
   ],
   "source": [
    "# Test the model GRU\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data_b in dlDataArrtest:\n",
    "        inputs, labels = data_b[0].to(torch.float32),data_b[1].to(torch.int64)\n",
    "        outputs = model(inputs)\n",
    "        # max returns (value ,index)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        #print(predicted, labels)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LSTM section"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size = 72\n",
    "sequence_length = 10240\n",
    "num_classes = 2\n",
    "# HYPERPARAMETERS\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "dataArrTrain = EegDataSetDask(trainData)\n",
    "dataArrTest = EegDataSetDask(testData)\n",
    "\n",
    "dlDataArrTrain = DataLoader(dataArrTrain, batch_size=batch_size, shuffle=True,num_workers=0,pin_memory=False)\n",
    "dlDataArrtest = DataLoader(dataArrTest, batch_size=batch_size, shuffle=True,num_workers=0,pin_memory=False)\n",
    "\n",
    "model = LSTMNet(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/222], Loss: 0.6939, Time : 59.77163600921631\n",
      "Epoch [1/1], Step [2/222], Loss: 0.6989, Time : 64.41405653953552\n",
      "Epoch [1/1], Step [3/222], Loss: 0.6927, Time : 66.36458945274353\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast():\n\u001B[1;32m---> 14\u001B[0m     outputs,h \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "Input \u001B[1;32mIn [24]\u001B[0m, in \u001B[0;36mLSTMNet.forward\u001B[1;34m(self, x, h)\u001B[0m\n\u001B[0;32m     12\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mreshape(x,(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m],x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]))\n\u001B[1;32m---> 13\u001B[0m out, h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out[:,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]))\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    760\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 761\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    762\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    763\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast():\n\u001B[0;32m     14\u001B[0m     outputs,h \u001B[38;5;241m=\u001B[39m model(inputs,h)\n\u001B[1;32m---> 15\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Backward and optimize\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mparameters():\n",
      "File \u001B[1;32m~\\.virtualenvs\\MachineMasteryTuto-A9SUx3Ht\\lib\\site-packages\\torch\\cuda\\amp\\autocast_mode.py:33\u001B[0m, in \u001B[0;36mautocast.__exit__\u001B[1;34m(self, exc_type, exc_val, exc_tb)\u001B[0m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__enter__\u001B[39m()\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# TODO: discuss a unified TorchScript-friendly API for autocast\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, exc_type: Any, exc_val: Any, exc_tb: Any):  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_jit_internal\u001B[38;5;241m.\u001B[39mis_scripting():\n\u001B[0;32m     35\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model LSTM\n",
    "n_total_steps = len(dlDataArrTrain)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "h = model.init_hidden(batch_size)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i, data_b in enumerate(dlDataArrTrain):\n",
    "        start = time()\n",
    "        inputs, labels = data_b[0].to(torch.float32),data_b[1].to(torch.int64)\n",
    "        h = tuple([e.data for e in h])\n",
    "        # Forward pass\n",
    "        # Runs the forward pass with autocasting.\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs,h = model(inputs,h)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        end=time()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}, Time : {end-start}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(net, 'lstm.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test the model STM\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data_b in dlDataArrtest:\n",
    "        inputs, labels = data_b[0].to(torch.float32),data_b[1].to(torch.int64)\n",
    "        outputs = model(inputs)\n",
    "        # max returns (value ,index)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        #print(predicted, labels)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}