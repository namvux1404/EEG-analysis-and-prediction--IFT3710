{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "852251da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "505e6cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_eeg_path = glob('Music Thinking/sub-*/ses-*/eeg/*.set')\n",
    "len(all_eeg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24273890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "behaviour_data = np.genfromtxt('Music Thinking/stimuli/Behavioural_data.txt')\n",
    "behaviour_data = behaviour_data[1:]\n",
    "\n",
    "labels = behaviour_data[:,2]\n",
    "for i in range(labels.shape[0]):\n",
    "    # Enjoyment level 1 or 2 -> enjoy the most\n",
    "    if labels[i] <= 2:\n",
    "        labels[i] = 1\n",
    "        \n",
    "    # Neutral or does not enjoy (enjoyment levels 3 to 5)\n",
    "    else:\n",
    "        labels[i] = 0\n",
    "        \n",
    "# The proportion of people liking/disliking the music is relatively the same.\n",
    "print(np.count_nonzero(labels == 1)) # LIKE\n",
    "print(np.count_nonzero(labels == 0)) # DISLIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23844f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "# Associate each path to the corresponding class (binary classification)\n",
    "like_path = []\n",
    "dislike_path = []\n",
    "\n",
    "for i in range(labels.shape[0]):\n",
    "    if labels[i] == 1:\n",
    "        like_path = np.append(like_path, all_eeg_path[i])\n",
    "    else:\n",
    "        dislike_path = np.append(dislike_path, all_eeg_path[i])\n",
    "\n",
    "## TEST\n",
    "# 20 INDIVIDUALS FOR TESTING\n",
    "\n",
    "like_path = like_path[0:10]\n",
    "dislike_path = dislike_path[0:10]\n",
    "        \n",
    "print(like_path.shape[0], dislike_path.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f4ff9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that reads EEG Data (set extension file)\n",
    "def read_set_data(path):\n",
    "    music_data = mne.io.read_raw_eeglab(path, preload = True)\n",
    "    #music_data.set_eeg_reference()\n",
    "    \n",
    "    epochs = mne.make_fixed_length_epochs(music_data, duration = 3, overlap = 2, preload = True)\n",
    "    music_array = epochs.get_data()\n",
    "    music_array = music_array[:,:,:750]\n",
    "    \n",
    "    number_epochs = 4\n",
    "    array_epochs = np.empty(number_epochs, dtype = object)\n",
    "\n",
    "    for i in range(number_epochs):\n",
    "        chosen_number = random.randint(0, music_array.shape[0]-1)\n",
    "        print(chosen_number)\n",
    "        array_epochs[i] = music_array[chosen_number]\n",
    "    \n",
    "    return array_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1b71c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "random.seed(0)\n",
    "\n",
    "like_epoch_array = np.empty((len(like_path)), dtype = object)\n",
    "dislike_epoch_array = np.empty((len(dislike_path)), dtype = object)\n",
    "\n",
    "for i in range(len(like_path)):\n",
    "    like_epoch_array[i] = read_set_data(like_path[i])\n",
    "    \n",
    "for i in range(len(dislike_path)):\n",
    "    dislike_epoch_array[i] = read_set_data(dislike_path[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ec0177fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "# Assign the labels for each epoch\n",
    "like_epoch_labels = np.empty((len(like_path)), dtype = object)\n",
    "dislike_epoch_labels = np.empty((len(dislike_path)), dtype = object)\n",
    "\n",
    "for i in range(len(like_path)):\n",
    "    like_epoch_labels[i] = len(like_epoch_array[i]) * [1]\n",
    "    \n",
    "for i in range(len(dislike_path)):\n",
    "    dislike_epoch_labels[i] = len(dislike_epoch_array[i]) * [0]\n",
    "    \n",
    "print(len(like_epoch_labels), len(dislike_epoch_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fedd9cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750,)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dislike_epoch_array[6][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b3a8bc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48,)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.hstack(np.append(like_epoch_array[0:6], dislike_epoch_array[0:6]))\n",
    "X_val = np.hstack(np.append(like_epoch_array[6:], dislike_epoch_array[6:]))\n",
    "\n",
    "y_train = np.hstack(np.append(like_epoch_labels[0:6], dislike_epoch_labels[0:6]))\n",
    "y_val = np.hstack(np.append(like_epoch_labels[6:], dislike_epoch_labels[6:]))\n",
    "\n",
    "X_train[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b7616628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 1, 129, 750) (32, 1, 129, 750) (48,) (32,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = np.zeros((X_train.shape[0], 1, 129, 750))\n",
    "X_val_tensor = np.zeros((X_val.shape[0], 1, 129, 750))\n",
    "\n",
    "for i in range(X_train_tensor.shape[0]):\n",
    "    X_train_tensor[i,0,:,:] = X_train[i]\n",
    "    \n",
    "for i in range(X_val_tensor.shape[0]):\n",
    "    X_val_tensor[i,0,:,:] = X_val[i]\n",
    "\n",
    "print(X_train_tensor.shape, X_val_tensor.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "22fb9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGTrain(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        #data loading\n",
    "        self.x = torch.from_numpy(X_train_tensor).float()\n",
    "        self.y = torch.from_numpy(y_train).long()\n",
    "        self.n_samples = len(y_train)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "96d65b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGVal(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        #data loading\n",
    "        self.x = torch.from_numpy(X_val_tensor).float()\n",
    "        self.y = torch.from_numpy(y_val).long()\n",
    "        self.n_samples = len(y_val)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "55aa4403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TESTING\n",
    "# Batch-size: let's test with 4 for now\n",
    "train_data = EEGTrain()\n",
    "train_dl = DataLoader(dataset = train_data, batch_size = 4, shuffle = True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dl))\n",
    "print(train_features.size(), train_labels.size())\n",
    "\n",
    "train_labels\n",
    "\n",
    "num_epochs = 2\n",
    "total_samples = len(train_data)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_dl):\n",
    "        #forward and backward pass, update our weights\n",
    "        print(f'epoch {epoch + 1}/{num_epochs}, step {i + 1}/{n_iterations}, inputs {inputs.shape}')\n",
    "        print(labels)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1503b",
   "metadata": {},
   "source": [
    "## ATTEMPT FOR RNN IMPLEMENTATION HAHA... :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "332cc5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "hidden_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 1\n",
    "batch_size = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 129\n",
    "sequence_length = 750\n",
    "num_layers = 2\n",
    "\n",
    "# DATASETS\n",
    "train_data = EEGTrain()\n",
    "train_dl = DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "val_data = EEGVal()\n",
    "val_dl = DataLoader(dataset = val_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "2c6eaf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        # x -> (batch_size, sequence_length, input_size)\n",
    "        \n",
    "        # or:\n",
    "        #self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # out -> (batch_size, sequence_length, hidden_size)\n",
    "        # out -> (N, 129, 128) ->> NOTE: CHANGE SEQUENCE_LENGTH AS 750 LATER (TRANPOSE THE TENSOR)\n",
    "        out = out[:, -1, :]\n",
    "        # out -> (N, 128)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "a78cc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a908b1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/10], Loss: 0.6650\n",
      "Epoch [1/1], Step [2/10], Loss: 0.5961\n",
      "Epoch [1/1], Step [3/10], Loss: 0.6840\n",
      "Epoch [1/1], Step [4/10], Loss: 0.6978\n",
      "Epoch [1/1], Step [5/10], Loss: 1.0363\n",
      "Epoch [1/1], Step [6/10], Loss: 0.8185\n",
      "Epoch [1/1], Step [7/10], Loss: 0.6746\n",
      "Epoch [1/1], Step [8/10], Loss: 0.9143\n",
      "Epoch [1/1], Step [9/10], Loss: 0.7299\n",
      "Epoch [1/1], Step [10/10], Loss: 0.6694\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(train_dl)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_dl):  \n",
    "        # origin shape: [N, 1, 28, 28]\n",
    "        # resized: [N, 28, 28]\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a40f4b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0]) tensor([0, 1, 0, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0]) tensor([1, 1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0]) tensor([0, 1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0]) tensor([1, 0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0]) tensor([0, 0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0]) tensor([1, 0, 1, 0, 0])\n",
      "tensor([0, 0]) tensor([1, 0])\n",
      "Accuracy of the network: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in val_dl:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        print(predicted, labels)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DOCUMENTATION:\n",
    "\n",
    "Accomplished tasks:\n",
    "-> Set datasets and dataloaders for Pytorch Neural networks' inputs\n",
    "-> Testing our very first RNN model ever with a very small sample_size (20 individuals to be exact)\n",
    "\n",
    "Upcoming steps...\n",
    "-> Transpose the matrix 129-750 (129 electrodes x 750 time points).\n",
    "-> Experiment and add new layers in RNN (add dropout rate, etc.). The model implemented was only one hidden layer.\n",
    "-> Experiment with a larger sample size in the cluster.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
