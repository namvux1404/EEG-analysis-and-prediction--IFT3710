{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16acca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82204ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array that stores all the set files for music thinking\n",
    "all_eeg_path = glob('Music Thinking/sub-*/ses-*/eeg/*.set')\n",
    "len(all_eeg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc8dd189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array for the labels\n",
    "behaviour_data = np.genfromtxt('Music Thinking/stimuli/Behavioural_data.txt')\n",
    "behaviour_data = behaviour_data[1:]\n",
    "\n",
    "labels = behaviour_data[:,2]\n",
    "for i in range(labels.shape[0]):\n",
    "    # Enjoyment level 1 or 2 -> enjoy the most\n",
    "    if labels[i] <= 2:\n",
    "        labels[i] = 1\n",
    "        \n",
    "    # Neutral or does not enjoy (enjoyment levels 3 to 5)\n",
    "    else:\n",
    "        labels[i] = 0\n",
    "        \n",
    "# The proportion of people liking/disliking the music is relatively the same.\n",
    "print(np.count_nonzero(labels == 1)) # LIKE\n",
    "print(np.count_nonzero(labels == 0)) # DISLIKE\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f117093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 128\n"
     ]
    }
   ],
   "source": [
    "# Associate each path to the corresponding class (binary classification)\n",
    "like_path = []\n",
    "dislike_path = []\n",
    "\n",
    "for i in range(labels.shape[0]):\n",
    "    if labels[i] == 1:\n",
    "        like_path = np.append(like_path, all_eeg_path[i])\n",
    "    else:\n",
    "        dislike_path = np.append(dislike_path, all_eeg_path[i])\n",
    "        \n",
    "print(like_path.shape[0], dislike_path.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aea20ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that reads EEG Data (set extension file)\n",
    "def read_set_data(path):\n",
    "    music_data = mne.io.read_raw_eeglab(path, preload = True)\n",
    "    music_data.set_eeg_reference()\n",
    "    \n",
    "    # Preprocessing (Filtering)\n",
    "    #music_data.filter(l_freq = 0.1, h_freq = 60)\n",
    "    \n",
    "    epochs = mne.make_fixed_length_epochs(music_data, duration = 4, overlap = 1)\n",
    "    music_array = epochs.get_data()\n",
    "    \n",
    "    print(music_array.shape)\n",
    "    return music_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31f8c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot visualization\n",
    "# ex = mne.io.read_raw_eeglab(all_eeg_path[0], preload = True)\n",
    "# ex.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08571e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (for cluster)\n",
    "%%capture\n",
    "#like_epochs_array = [read_set_data(i) for i in like_path]\n",
    "#dislike_epochs_array = [read_set_data(i) for i in dislike_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca07a6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
